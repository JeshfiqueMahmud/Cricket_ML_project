{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12133777,"sourceType":"datasetVersion","datasetId":7641220},{"sourceId":436085,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":355670,"modelId":376970}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-15T15:19:47.886726Z","iopub.execute_input":"2025-06-15T15:19:47.886917Z","iopub.status.idle":"2025-06-15T15:19:49.245814Z","shell.execute_reply.started":"2025-06-15T15:19:47.886900Z","shell.execute_reply":"2025-06-15T15:19:49.245075Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/cricket-dataset/y_train1.csv\n/kaggle/input/cricket-dataset/X_train1.csv\n/kaggle/input/cricket-dataset/X_test1.csv\n/kaggle/input/cricket-dataset/final_odi_matches_with_full_weather2.csv\n/kaggle/input/cricket-dataset/y_test1.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install tabpfn\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T06:04:21.811796Z","iopub.execute_input":"2025-06-15T06:04:21.812289Z","iopub.status.idle":"2025-06-15T06:05:58.002475Z","shell.execute_reply.started":"2025-06-15T06:04:21.812265Z","shell.execute_reply":"2025-06-15T06:05:58.001547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport joblib\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tabpfn import TabPFNClassifier\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/cricket-dataset/final_odi_matches_with_full_weather2.csv\")\n\n# Clean and engineer\ndf = df.dropna(subset=['Match Winner', 'Team1 Name', 'Team2 Name', 'Avg_Temp_C'])\ndf['Avg_Temp_C'] = df['Avg_Temp_C'].replace(-99, np.nan)\ndf = df.dropna(subset=['Avg_Temp_C'])\n\ndf.rename(columns={\n    'Team1 Name': 'Team1',\n    'Team2 Name': 'Team2',\n    'Match Winner': 'Winner',\n    'Toss Winner': 'TossWinner',\n    'Match Venue (Country)': 'VenueCountry'\n}, inplace=True)\n\ndf['home_advantage'] = df.apply(\n    lambda row: 1 if pd.notna(row['VenueCountry']) and row['VenueCountry'].lower() in row['Team1'].lower() else 0,\n    axis=1\n)\ndf['won_toss'] = df.apply(lambda row: 1 if row['TossWinner'] == row['Team1'] else 0, axis=1)\n\nteam_rank = {\n    'India': 1, 'New Zealand': 2, 'Australia': 3, 'Sri Lanka': 4,\n    'Pakistan': 5, 'South Africa': 6, 'Afghanistan': 7,\n    'England': 8, 'West Indies': 9, 'Bangladesh': 10\n}\ndf['team1_rank'] = df['Team1'].map(team_rank)\ndf['team2_rank'] = df['Team2'].map(team_rank)\ndf = df.dropna(subset=['team1_rank', 'team2_rank'])\ndf['rank_diff'] = df['team2_rank'] - df['team1_rank']\ndf['target'] = df.apply(lambda row: 1 if row['Winner'] == row['Team1'] else 0, axis=1)\n\n# Final features\nfeatures = ['Avg_Temp_C', 'home_advantage', 'won_toss', 'team1_rank', 'team2_rank', 'rank_diff']\nX = df[features]\ny = df['target']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n\n# Train TabPFN\ntabpfn_clf = TabPFNClassifier(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntabpfn_clf.fit(X_train, y_train)\n\n# Predict & Evaluate\ny_pred = tabpfn_clf.predict(X_test)\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n# Train TabPFN\ntabpfn_clf = TabPFNClassifier(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntabpfn_clf.fit(X_train, y_train)\n\n# Save model to disk\njoblib.dump(tabpfn_clf, \"tabpfn_model.pkl\")\nprint(\"✅ Model saved as tabpfn_model.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T06:08:49.460413Z","iopub.execute_input":"2025-06-15T06:08:49.460701Z","iopub.status.idle":"2025-06-15T06:08:51.866652Z","shell.execute_reply.started":"2025-06-15T06:08:49.460681Z","shell.execute_reply":"2025-06-15T06:08:51.866006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cricket_ensemble_pipeline.py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom tabpfn import TabPFNClassifier\nimport torch\nimport joblib\n\n# ------------------ Step 1: Load & Clean ------------------\ndf = pd.read_csv(\"/kaggle/input/cricket-dataset/final_odi_matches_with_full_weather2.csv\")\n\ndf = df.dropna(subset=['Match Winner', 'Team1 Name', 'Team2 Name'])\ndf['Avg_Temp_C'] = df['Avg_Temp_C'].replace(-99, np.nan)\ndf = df.dropna(subset=['Avg_Temp_C'])\n\ndf.rename(columns={\n    'Team1 Name': 'Team1',\n    'Team2 Name': 'Team2',\n    'Match Winner': 'Winner',\n    'Toss Winner': 'TossWinner',\n    'Match Venue (Country)': 'VenueCountry'\n}, inplace=True)\n\n# ------------------ Step 2: Feature Engineering ------------------\ndf['home_advantage'] = df.apply(lambda row: 1 if pd.notna(row['VenueCountry']) and row['VenueCountry'].lower() in row['Team1'].lower() else 0, axis=1)\ndf['won_toss'] = df.apply(lambda row: 1 if row['TossWinner'] == row['Team1'] else 0, axis=1)\n\nteam_rank = {\n    'India': 1, 'New Zealand': 2, 'Australia': 3, 'Sri Lanka': 4,\n    'Pakistan': 5, 'South Africa': 6, 'Afghanistan': 7,\n    'England': 8, 'West Indies': 9, 'Bangladesh': 10\n}\ndf['team1_rank'] = df['Team1'].map(team_rank)\ndf['team2_rank'] = df['Team2'].map(team_rank)\ndf = df.dropna(subset=['team1_rank', 'team2_rank'])\ndf['rank_diff'] = df['team2_rank'] - df['team1_rank']\ndf['target'] = df.apply(lambda row: 1 if row['Winner'] == row['Team1'] else 0, axis=1)\n\n# ------------------ Step 3: Preprocessing ------------------\nfeatures = ['Avg_Temp_C', 'home_advantage', 'won_toss', 'team1_rank', 'team2_rank', 'rank_diff']\nX = df[features]\ny = df['target']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n)\n\n# ------------------ Step 4: Model Training ------------------\n# XGBoost with hyperparameter tuning\nxgb_params = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [5, 7, 10],\n    'learning_rate': [0.01, 0.05, 0.1],\n    'subsample': [0.8, 1.0],\n    'colsample_bytree': [0.8, 1.0]\n}\nxgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\nxgb_grid = GridSearchCV(xgb, xgb_params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\nxgb_grid.fit(X_train, y_train)\nxgb_probs = xgb_grid.predict_proba(X_test)[:, 1]\n\n# Random Forest with hyperparameter tuning\nrf_params = {\n    'n_estimators': [100, 200],\n    'max_depth': [10, 15, None],\n    'min_samples_split': [2, 5, 10]\n}\nrf = RandomForestClassifier(random_state=42)\nrf_grid = GridSearchCV(rf, rf_params, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\nrf_grid.fit(X_train, y_train)\nrf_probs = rf_grid.predict_proba(X_test)[:, 1]\n\n# TabPFN (no tuning required)\ntabpfn = TabPFNClassifier(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntabpfn.fit(X_train, y_train)\ntabpfn_probs = tabpfn.predict_proba(X_test)[:, 1]\n\n# ------------------ Step 5: Ensemble Prediction ------------------\n# Weighted average\nensemble_probs = (0.4 * xgb_probs) + (0.3 * rf_probs) + (0.3 * tabpfn_probs)\nensemble_preds = (ensemble_probs > 0.5).astype(int)\n\n# ------------------ Step 6: Evaluation ------------------\nprint(\"\\n\\n🎯 Ensemble Accuracy:\", accuracy_score(y_test, ensemble_preds))\nprint(\"\\n📊 Classification Report:\")\nprint(classification_report(y_test, ensemble_preds))\n\n# ------------------ Step 7: Save Models ------------------\njoblib.dump(xgb_grid.best_estimator_, \"xgb_model.pkl\")\njoblib.dump(rf_grid.best_estimator_, \"rf_model.pkl\")\njoblib.dump(tabpfn, \"tabpfn_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T06:25:12.126324Z","iopub.execute_input":"2025-06-15T06:25:12.126621Z","iopub.status.idle":"2025-06-15T06:25:43.410466Z","shell.execute_reply.started":"2025-06-15T06:25:12.126601Z","shell.execute_reply":"2025-06-15T06:25:43.409722Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cricket_ensemble_pipeline_optimized.py\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom tabpfn import TabPFNClassifier\nimport torch\nimport joblib\n\n# ------------------ Step 1: Load & Clean ------------------\ndf = pd.read_csv(\"/kaggle/input/cricket-dataset/final_odi_matches_with_full_weather2.csv\")\n\ndf = df.dropna(subset=['Match Winner', 'Team1 Name', 'Team2 Name'])\ndf['Avg_Temp_C'] = df['Avg_Temp_C'].replace(-99, np.nan)\ndf = df.dropna(subset=['Avg_Temp_C'])\n\ndf.rename(columns={\n    'Team1 Name': 'Team1',\n    'Team2 Name': 'Team2',\n    'Match Winner': 'Winner',\n    'Toss Winner': 'TossWinner',\n    'Match Venue (Country)': 'VenueCountry'\n}, inplace=True)\n\n# ------------------ Step 2: Feature Engineering ------------------\ndf['home_advantage'] = df.apply(lambda row: 1 if pd.notna(row['VenueCountry']) and row['VenueCountry'].lower() in row['Team1'].lower() else 0, axis=1)\ndf['won_toss'] = df.apply(lambda row: 1 if row['TossWinner'] == row['Team1'] else 0, axis=1)\n\nteam_rank = {\n    'India': 1, 'New Zealand': 2, 'Australia': 3, 'Sri Lanka': 4,\n    'Pakistan': 5, 'South Africa': 6, 'Afghanistan': 7,\n    'England': 8, 'West Indies': 9, 'Bangladesh': 10\n}\ndf['team1_rank'] = df['Team1'].map(team_rank)\ndf['team2_rank'] = df['Team2'].map(team_rank)\ndf = df.dropna(subset=['team1_rank', 'team2_rank'])\ndf['rank_diff'] = df['team2_rank'] - df['team1_rank']\ndf['rank_ratio'] = df['team1_rank'] / df['team2_rank']\ndf['target'] = df.apply(lambda row: 1 if row['Winner'] == row['Team1'] else 0, axis=1)\n\n# ------------------ Step 3: Preprocessing ------------------\nfeatures = ['Avg_Temp_C', 'home_advantage', 'won_toss', 'team1_rank', 'team2_rank', 'rank_diff', 'rank_ratio']\nX = df[features]\ny = df['target']\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n)\n\n# ------------------ Step 4: Model Training ------------------\nkf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n\n# XGBoost\nxgb_params = {\n    'n_estimators': [100, 200],\n    'max_depth': [5, 7],\n    'learning_rate': [0.05, 0.1],\n    'subsample': [0.8, 1.0],\n    'colsample_bytree': [0.8, 1.0]\n}\nxgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\nxgb_grid = GridSearchCV(xgb, xgb_params, cv=kf, scoring='accuracy', verbose=1, n_jobs=-1)\nxgb_grid.fit(X_train, y_train)\nxgb_probs = xgb_grid.predict_proba(X_test)[:, 1]\n\n# Random Forest\nrf_params = {\n    'n_estimators': [100, 200],\n    'max_depth': [10, None],\n    'min_samples_split': [2, 5]\n}\nrf = RandomForestClassifier(random_state=42)\nrf_grid = GridSearchCV(rf, rf_params, cv=kf, scoring='accuracy', verbose=1, n_jobs=-1)\nrf_grid.fit(X_train, y_train)\nrf_probs = rf_grid.predict_proba(X_test)[:, 1]\n\n# TabPFN\ntabpfn = TabPFNClassifier(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntabpfn.fit(X_train, y_train)\ntabpfn_probs = tabpfn.predict_proba(X_test)[:, 1]\n\n# ------------------ Step 5: Ensemble via Meta Learner ------------------\nmeta_X = np.vstack((xgb_probs, rf_probs, tabpfn_probs)).T\nmeta_clf = LogisticRegression()\nmeta_clf.fit(meta_X, y_test)\nmeta_probs = meta_clf.predict_proba(meta_X)[:, 1]\nensemble_preds = (meta_probs > 0.5).astype(int)\n\n# ------------------ Step 6: Evaluation ------------------\nprint(\"\\n\\n🎯 Ensemble Accuracy:\", accuracy_score(y_test, ensemble_preds))\nprint(\"\\n📊 Classification Report:\")\nprint(classification_report(y_test, ensemble_preds))\n\n# ------------------ Step 7: Save Models ------------------\njoblib.dump(xgb_grid.best_estimator_, \"xgb_model.pkl\")\njoblib.dump(rf_grid.best_estimator_, \"rf_model.pkl\")\njoblib.dump(tabpfn, \"tabpfn_model.pkl\")\njoblib.dump(meta_clf, \"meta_ensemble_model.pkl\")\njoblib.dump(scaler, \"scaler.pkl\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T06:24:03.822284Z","iopub.execute_input":"2025-06-15T06:24:03.822555Z","iopub.status.idle":"2025-06-15T06:24:14.435835Z","shell.execute_reply.started":"2025-06-15T06:24:03.822535Z","shell.execute_reply":"2025-06-15T06:24:14.435075Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install autogluon\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:41:43.130119Z","iopub.execute_input":"2025-06-15T08:41:43.130409Z","iopub.status.idle":"2025-06-15T08:41:48.654354Z","shell.execute_reply.started":"2025-06-15T08:41:43.130373Z","shell.execute_reply":"2025-06-15T08:41:48.653598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install xgboost==1.7.6 scikit-learn==1.3.2 --upgrade\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:38:54.893064Z","iopub.execute_input":"2025-06-15T08:38:54.893382Z","iopub.status.idle":"2025-06-15T08:39:10.305706Z","shell.execute_reply.started":"2025-06-15T08:38:54.893347Z","shell.execute_reply":"2025-06-15T08:39:10.304885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!apt-get install -y graphviz graphviz-dev\n!pip install pygraphviz\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:42:23.576159Z","iopub.execute_input":"2025-06-15T08:42:23.576494Z","iopub.status.idle":"2025-06-15T08:42:28.827705Z","shell.execute_reply.started":"2025-06-15T08:42:23.576468Z","shell.execute_reply":"2025-06-15T08:42:28.826744Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cricket_autogluon_pipeline.py\nimport pandas as pd\nfrom autogluon.tabular import TabularPredictor\n\n# ------------------ Step 1: Load & Clean ------------------\ndf = pd.read_csv(\"/kaggle/input/cricket-dataset/final_odi_matches_with_full_weather2.csv\")\ndf = df.dropna(subset=['Match Winner', 'Team1 Name', 'Team2 Name'])\ndf['Avg_Temp_C'] = df['Avg_Temp_C'].replace(-99, pd.NA)\ndf = df.dropna(subset=['Avg_Temp_C'])\n\ndf.rename(columns={\n    'Team1 Name': 'Team1',\n    'Team2 Name': 'Team2',\n    'Match Winner': 'Winner',\n    'Toss Winner': 'TossWinner',\n    'Match Venue (Country)': 'VenueCountry'\n}, inplace=True)\n\n# ------------------ Step 2: Feature Engineering ------------------\ndf['home_advantage'] = df.apply(lambda row: 1 if pd.notna(row['VenueCountry']) and row['VenueCountry'].lower() in row['Team1'].lower() else 0, axis=1)\ndf['won_toss'] = df.apply(lambda row: 1 if row['TossWinner'] == row['Team1'] else 0, axis=1)\nteam_rank = {\n    'India': 1, 'New Zealand': 2, 'Australia': 3, 'Sri Lanka': 4,\n    'Pakistan': 5, 'South Africa': 6, 'Afghanistan': 7,\n    'England': 8, 'West Indies': 9, 'Bangladesh': 10\n}\ndf['team1_rank'] = df['Team1'].map(team_rank)\ndf['team2_rank'] = df['Team2'].map(team_rank)\ndf = df.dropna(subset=['team1_rank', 'team2_rank'])\n\ndf['rank_diff'] = df['team2_rank'] - df['team1_rank']\ndf['target'] = df.apply(lambda row: 1 if row['Winner'] == row['Team1'] else 0, axis=1)\n\n# ------------------ Step 3: Prepare Dataset for AutoGluon ------------------\nfeatures = ['Avg_Temp_C', 'home_advantage', 'won_toss', 'team1_rank', 'team2_rank', 'rank_diff']\ntarget = 'target'\ndata = df[features + [target]]\n\n# Split train/test\ntrain_data = data.sample(frac=0.8, random_state=42)\ntest_data = data.drop(train_data.index)\n\n# ------------------ Step 4: AutoGluon Training ------------------\npredictor = TabularPredictor(label=target, eval_metric='accuracy', path='autogluon_models')\npredictor.fit(train_data, time_limit=600, presets='best_quality')  # 10 min max\n\n# ------------------ Step 5: Evaluation ------------------\nprint(\"\\n📊 AutoGluon Evaluation:\")\nperformance = predictor.evaluate(test_data)\n\n# ------------------ Step 6: Best Model & Ensemble Info ------------------\nlb = predictor.leaderboard(silent=True)\nbest_model = lb.loc[0, 'model']\nprint(\"🏆 Best Model Used:\", best_model)\n\n# If running in Jupyter, you can use:\npredictor.plot_ensemble_model()\n\n# ------------------ Step 7: Save Model ------------------\nimport joblib\n\n# Save AutoGluon predictor directory path as a joblib object\njoblib.dump(predictor, 'autogluon_predictor.pkl')\nprint(\"\\n✅ Predictor also saved as autogluon_predictor.pkl\")\n\npredictor.save()\nprint(\"\\n✅ Model saved at: autogluon_models/\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T07:46:56.532661Z","iopub.execute_input":"2025-06-15T07:46:56.533053Z","iopub.status.idle":"2025-06-15T07:56:59.944459Z","shell.execute_reply.started":"2025-06-15T07:46:56.533024Z","shell.execute_reply":"2025-06-15T07:56:59.943783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cricket_autogluon_pipeline.py\nimport pandas as pd\nfrom autogluon.tabular import TabularPredictor\n\n# ------------------ Step 1: Load & Clean ------------------\ndf = pd.read_csv(\"/kaggle/input/cricket-dataset/final_odi_matches_with_full_weather2.csv\")\n\ndf = df.dropna(subset=['Match Winner', 'Team1 Name', 'Team2 Name'])\ndf['Avg_Temp_C'] = df['Avg_Temp_C'].replace(-99, pd.NA)\ndf = df.dropna(subset=['Avg_Temp_C'])\n\ndf.rename(columns={\n    'Team1 Name': 'Team1',\n    'Team2 Name': 'Team2',\n    'Match Winner': 'Winner',\n    'Toss Winner': 'TossWinner',\n    'Match Venue (Country)': 'VenueCountry'\n}, inplace=True)\n\n# ------------------ Step 2: Feature Engineering ------------------\ndf['home_advantage'] = df.apply(lambda row: 1 if pd.notna(row['VenueCountry']) and row['VenueCountry'].lower() in row['Team1'].lower() else 0, axis=1)\ndf['won_toss'] = df.apply(lambda row: 1 if row['TossWinner'] == row['Team1'] else 0, axis=1)\n\nteam_rank = {\n    'India': 1, 'New Zealand': 2, 'Australia': 3, 'Sri Lanka': 4,\n    'Pakistan': 5, 'South Africa': 6, 'Afghanistan': 7,\n    'England': 8, 'West Indies': 9, 'Bangladesh': 10\n}\ndf['team1_rank'] = df['Team1'].map(team_rank)\ndf['team2_rank'] = df['Team2'].map(team_rank)\ndf = df.dropna(subset=['team1_rank', 'team2_rank'])\n\ndf['rank_diff'] = df['team2_rank'] - df['team1_rank']\ndf['target'] = df.apply(lambda row: 1 if row['Winner'] == row['Team1'] else 0, axis=1)\n\n# ------------------ Step 3: Prepare Dataset for AutoGluon ------------------\nfeatures = ['Avg_Temp_C', 'home_advantage', 'won_toss', 'team1_rank', 'team2_rank', 'rank_diff']\ntarget = 'target'\ndata = df[features + [target]]\n\n# Split train/test\ntrain_data = data.sample(frac=0.8, random_state=42)\ntest_data = data.drop(train_data.index)\n\n# ------------------ Step 4: AutoGluon Training ------------------\npredictor = TabularPredictor(label=target, eval_metric='accuracy', path='autogluon_models')\npredictor.fit(train_data, time_limit=600, presets='best_quality')  # Best models, 10 mins\n\n# ------------------ Step 5: Evaluation ------------------\nperformance = predictor.evaluate(test_data)\nprint(\"🎯 AutoGluon Performance:\")\nprint(performance)\n\n# ------------------ Step 6: Leaderboard & Best Model ------------------\nprint(\"\\n📊 Leaderboard:\")\nleaderboard_df = predictor.leaderboard(test_data, silent=True)\nprint(leaderboard_df)\n\n# Get best model\nbest_model = leaderboard_df.loc[leaderboard_df['score_test'].idxmax(), 'model']\nprint(f\"\\n🏆 Best Model Used: {best_model}\")\n\n# ------------------ Step 7: Save Predictor ------------------\npredictor.save()\nprint(\"\\n✅ Predictor saved to 'autogluon_models' folder\")\n\n# ------------------ Optional: Plot Ensemble Network ------------------\ntry:\n    predictor.plot_ensemble_model()\nexcept ImportError:\n    print(\"\\n📉 To visualize ensemble structure, install pygraphviz:\\n\"\n          \"!apt-get install -y graphviz graphviz-dev && pip install pygraphviz\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T08:43:54.514452Z","iopub.execute_input":"2025-06-15T08:43:54.514727Z","iopub.status.idle":"2025-06-15T08:53:59.268766Z","shell.execute_reply.started":"2025-06-15T08:43:54.514707Z","shell.execute_reply":"2025-06-15T08:53:59.268109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# cricket_autogluon_full_pipeline.py\nimport pandas as pd\nfrom autogluon.tabular import TabularPredictor\nfrom sklearn.model_selection import KFold\nimport numpy as np\nimport os\n\n# ------------------ Step 1: Load Dataset ------------------\ndf = pd.read_csv(\"/kaggle/input/cricket-dataset/final_odi_matches_with_full_weather2.csv\")\n\ndf = df.dropna(subset=['Match Winner', 'Team1 Name', 'Team2 Name'])\ndf['Avg_Temp_C'] = df['Avg_Temp_C'].replace(-99, pd.NA)\ndf = df.dropna(subset=['Avg_Temp_C'])\n\ndf.rename(columns={\n    'Team1 Name': 'Team1',\n    'Team2 Name': 'Team2',\n    'Match Winner': 'Winner',\n    'Toss Winner': 'TossWinner',\n    'Match Venue (Country)': 'VenueCountry',\n    'Toss Winner Choice': 'TossDecision',\n}, inplace=True)\n\n# ------------------ Step 2: Feature Engineering ------------------\ndf['home_advantage'] = df.apply(lambda row: 1 if pd.notna(row['VenueCountry']) and row['VenueCountry'].lower() in row['Team1'].lower() else 0, axis=1)\ndf['won_toss'] = df.apply(lambda row: 1 if row['TossWinner'] == row['Team1'] else 0, axis=1)\ndf['toss_bat'] = df.apply(lambda row: 1 if row['TossDecision'].lower() == 'bat' and row['TossWinner'] == row['Team1'] else 0, axis=1)\n\nteam_rank = {\n    'India': 1, 'New Zealand': 2, 'Australia': 3, 'Sri Lanka': 4,\n    'Pakistan': 5, 'South Africa': 6, 'Afghanistan': 7,\n    'England': 8, 'West Indies': 9, 'Bangladesh': 10\n}\ndf['team1_rank'] = df['Team1'].map(team_rank)\ndf['team2_rank'] = df['Team2'].map(team_rank)\ndf = df.dropna(subset=['team1_rank', 'team2_rank'])\n\ndf['rank_diff'] = df['team2_rank'] - df['team1_rank']\ndf['month'] = pd.to_datetime(df['Match Date'], errors='coerce').dt.month\ndf = df.dropna(subset=['month'])\n\ndf['target'] = df.apply(lambda row: 1 if row['Winner'] == row['Team1'] else 0, axis=1)\n\n# ------------------ Step 3: Select Features ------------------\nfeatures = [\n    'Avg_Temp_C', 'home_advantage', 'won_toss', 'toss_bat',\n    'team1_rank', 'team2_rank', 'rank_diff', 'month'\n]\ntarget = 'target'\ndata = df[features + [target]]\n\n# ------------------ Step 4: K-Fold Cross-Validation ------------------\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\ncv_scores = []\nfold = 1\n\nfor train_idx, test_idx in kf.split(data):\n    print(f\"\\n📂 Training Fold {fold}...\")\n    train_data = data.iloc[train_idx]\n    test_data = data.iloc[test_idx]\n\n    fold_path = f\"autogluon_cv_models/fold_{fold}/\"\n    os.makedirs(fold_path, exist_ok=True)\n\n    predictor = TabularPredictor(label=target, path=fold_path, eval_metric='accuracy').fit(\n        train_data=train_data,\n        time_limit=600,\n        presets='best_quality',\n        num_stack_levels=2,\n        num_bag_folds=5,\n        verbosity=2\n    )\n\n    performance = predictor.evaluate(test_data)\n    print(\"🎯 Fold Performance:\", performance)\n    cv_scores.append(performance['accuracy'])\n    fold += 1\n\n# ------------------ Step 5: CV Results ------------------\nprint(\"\\n📊 Cross-Validation Accuracy Scores:\", cv_scores)\nprint(f\"✅ Average CV Accuracy: {np.mean(cv_scores):.4f}\")\n\n# ------------------ Step 6: Train Final Model on All Data ------------------\nprint(\"\\n🚀 Training Final Model on Full Dataset...\")\nfinal_path = \"autogluon_final_model/\"\nos.makedirs(final_path, exist_ok=True)\n\npredictor_final = TabularPredictor(label=target, path=final_path, eval_metric='accuracy').fit(\n    train_data=data,\n    time_limit=900,\n    presets='best_quality',\n    num_stack_levels=2,\n    num_bag_folds=5,\n    verbosity=2\n)\npredictor_final.save()\nprint(\"\\n✅ Final model saved to:\", final_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T09:31:23.609253Z","iopub.execute_input":"2025-06-15T09:31:23.611588Z","iopub.status.idle":"2025-06-15T10:36:46.845565Z","shell.execute_reply.started":"2025-06-15T09:31:23.611553Z","shell.execute_reply":"2025-06-15T10:36:46.844857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# evaluate_cricket_model.py\nimport pandas as pd\nfrom autogluon.tabular import TabularPredictor\n\n# ------------------ Step 1: Load Final Model ------------------\npredictor = TabularPredictor.load(\"autogluon_final_model/\")\nprint(\"✅ Final model loaded.\")\n\n# ------------------ Step 2: Load Dataset ------------------\ndf = pd.read_csv(\"/kaggle/input/cricket-dataset/final_odi_matches_with_full_weather2.csv\")\n\n# Apply same preprocessing\ndf = df.dropna(subset=['Match Winner', 'Team1 Name', 'Team2 Name'])\ndf['Avg_Temp_C'] = df['Avg_Temp_C'].replace(-99, pd.NA)\ndf = df.dropna(subset=['Avg_Temp_C'])\n\ndf.rename(columns={\n    'Team1 Name': 'Team1',\n    'Team2 Name': 'Team2',\n    'Match Winner': 'Winner',\n    'Toss Winner': 'TossWinner',\n    'Match Venue (Country)': 'VenueCountry',\n    'Toss Winner Choice': 'TossDecision',\n}, inplace=True)\n\ndf['home_advantage'] = df.apply(lambda row: 1 if pd.notna(row['VenueCountry']) and row['VenueCountry'].lower() in row['Team1'].lower() else 0, axis=1)\ndf['won_toss'] = df.apply(lambda row: 1 if row['TossWinner'] == row['Team1'] else 0, axis=1)\ndf['toss_bat'] = df.apply(lambda row: 1 if row['TossDecision'].lower() == 'bat' and row['TossWinner'] == row['Team1'] else 0, axis=1)\n\nteam_rank = {\n    'India': 1, 'New Zealand': 2, 'Australia': 3, 'Sri Lanka': 4,\n    'Pakistan': 5, 'South Africa': 6, 'Afghanistan': 7,\n    'England': 8, 'West Indies': 9, 'Bangladesh': 10\n}\ndf['team1_rank'] = df['Team1'].map(team_rank)\ndf['team2_rank'] = df['Team2'].map(team_rank)\ndf = df.dropna(subset=['team1_rank', 'team2_rank'])\n\ndf['rank_diff'] = df['team2_rank'] - df['team1_rank']\ndf['month'] = pd.to_datetime(df['Match Date'], errors='coerce').dt.month\ndf = df.dropna(subset=['month'])\n\ndf['target'] = df.apply(lambda row: 1 if row['Winner'] == row['Team1'] else 0, axis=1)\n\n# ------------------ Step 3: Define Features & Evaluate ------------------\nfeatures = [\n    'Avg_Temp_C', 'home_advantage', 'won_toss', 'toss_bat',\n    'team1_rank', 'team2_rank', 'rank_diff', 'month'\n]\ndata = df[features + ['target']]\n\nperformance = predictor.evaluate(data)\nprint(\"\\n🎯 Full Dataset Evaluation:\")\nfor metric, value in performance.items():\n    print(f\"{metric}: {value:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T10:46:15.806793Z","iopub.execute_input":"2025-06-15T10:46:15.807476Z","iopub.status.idle":"2025-06-15T10:46:21.681541Z","shell.execute_reply.started":"2025-06-15T10:46:15.807445Z","shell.execute_reply":"2025-06-15T10:46:21.680578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# predict_new_match.py\nimport pandas as pd\nfrom autogluon.tabular import TabularPredictor\n\n# ------------------ Step 1: Load Final Model ------------------\npredictor = TabularPredictor.load(\"autogluon_final_model/\")\nprint(\"✅ Model loaded for prediction.\")\n\n# ------------------ Step 2: Define New Match Scenario ------------------\n# Sample match info (replace with your actual match data)\nnew_match = pd.DataFrame([{\n    'Avg_Temp_C': 28,\n    'home_advantage': 1,  # 1 if Team1 is playing in their home country\n    'won_toss': 1,        # 1 if Team1 won the toss\n    'toss_bat': 1,        # 1 if Team1 won the toss and chose to bat\n    'team1_rank': 1,      # ICC rank of Team1\n    'team2_rank': 3,      # ICC rank of Team2\n    'rank_diff': 3 - 1,   # team2_rank - team1_rank\n    'month': 10           # October\n}])\n\n# ------------------ Step 3: Predict ------------------\nprediction = predictor.predict(new_match)\nprobabilities = predictor.predict_proba(new_match)\n\n# ------------------ Step 4: Display Results ------------------\nprint(\"\\n🔮 Prediction Result:\")\nprint(\"Team1 Wins\" if prediction[0] == 1 else \"Team2 Wins\")\nprint(\"\\n📊 Probabilities:\")\nprint(probabilities)\n\n# Optional: Save to CSV\n# new_match['predicted_winner'] = prediction\n# new_match.to_csv(\"new_match_prediction.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T10:48:29.029185Z","iopub.execute_input":"2025-06-15T10:48:29.029767Z","iopub.status.idle":"2025-06-15T10:48:32.520843Z","shell.execute_reply.started":"2025-06-15T10:48:29.029743Z","shell.execute_reply":"2025-06-15T10:48:32.520059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Zip the uploaded model from input into working\nshutil.make_archive(\n    base_name=\"/kaggle/working/autogluon_final_model\",      # this is where ZIP will be saved\n    format='zip',                                            # zip format\n    root_dir=\"/kaggle/input/dd/other/default/1/autogluon_final_model\"        # your uploaded model path\n)\n\nprint(\"✅ Model zipped to /kaggle/working/autogluon_final_model.zip\")\n","metadata":{"trusted":true},"outputs":[{"name":"stdout","text":"✅ Model zipped to /kaggle/working/autogluon_final_model.zip\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import shutil\n\n# Zip the uploaded model from input into working\nshutil.make_archive(\n    base_name=\"/kaggle/working/autogluon_model\",      # this is where ZIP will be saved\n    format='zip',                                            # zip format\n    root_dir=\"/kaggle/input/dd/other/default/1/autogluon_models\"        # your uploaded model path\n)\n\nprint(\"✅ Model zipped to /kaggle/working/autogluon_final_model.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T15:45:06.826359Z","iopub.execute_input":"2025-06-15T15:45:06.826862Z","iopub.status.idle":"2025-06-15T15:45:25.178767Z","shell.execute_reply.started":"2025-06-15T15:45:06.826835Z","shell.execute_reply":"2025-06-15T15:45:25.178063Z"}},"outputs":[{"name":"stdout","text":"✅ Model zipped to /kaggle/working/autogluon_final_model.zip\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import shutil\n\n# Zip the uploaded model from input into working\nshutil.make_archive(\n    base_name=\"/kaggle/working/autogluon_model-CV\",      # this is where ZIP will be saved\n    format='zip',                                            # zip format\n    root_dir=\"/kaggle/input/dd/other/default/1/autogluon_cv_models\"        # your uploaded model path\n)\n\nprint(\"✅ Model zipped to /kaggle/working/autogluon_final_model.zip\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T15:51:24.783992Z","iopub.execute_input":"2025-06-15T15:51:24.784307Z","iopub.status.idle":"2025-06-15T15:53:12.390152Z","shell.execute_reply.started":"2025-06-15T15:51:24.784287Z","shell.execute_reply":"2025-06-15T15:53:12.389304Z"}},"outputs":[{"name":"stdout","text":"✅ Model zipped to /kaggle/working/autogluon_final_model.zip\n","output_type":"stream"}],"execution_count":9}]}