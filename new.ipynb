{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b3ed6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: Counter({1: 2125, 0: 2114})\n",
      "✅ Preprocessing complete. Saved to 'preprocessed_cricket_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "# ------------------ Step 1: Load & Clean ------------------\n",
    "df = pd.read_csv(\"final_odi_matches_with_full_weather2.csv\")\n",
    "\n",
    "# Drop rows with critical missing values\n",
    "df = df.dropna(subset=['Match Winner', 'Team1 Name', 'Team2 Name'])\n",
    "\n",
    "# Replace temperature placeholder -99 with NaN and drop those rows\n",
    "df['Avg_Temp_C'] = pd.to_numeric(df['Avg_Temp_C'], errors='coerce')\n",
    "df = df[df['Avg_Temp_C'] != -99]\n",
    "df = df.dropna(subset=['Avg_Temp_C'])\n",
    "\n",
    "# Rename columns for simplicity\n",
    "df.rename(columns={\n",
    "    'Team1 Name': 'Team1',\n",
    "    'Team2 Name': 'Team2',\n",
    "    'Match Winner': 'Winner',\n",
    "    'Toss Winner': 'TossWinner',\n",
    "    'Match Venue (Country)': 'VenueCountry'\n",
    "}, inplace=True)\n",
    "\n",
    "# ------------------ Step 2: Feature Engineering ------------------\n",
    "\n",
    "# Home advantage: check if venue country matches Team1\n",
    "df['home_advantage'] = df.apply(\n",
    "    lambda row: 1 if pd.notna(row['VenueCountry']) and row['VenueCountry'].lower() in row['Team1'].lower() else 0, axis=1\n",
    ")\n",
    "\n",
    "# Toss won by Team1\n",
    "df['won_toss'] = df.apply(lambda row: 1 if row['TossWinner'] == row['Team1'] else 0, axis=1)\n",
    "\n",
    "# Fake ICC rankings (adjust as needed)\n",
    "icc_ranks = {\n",
    "    'India': 1,\n",
    "    'New Zealand': 2,\n",
    "    'Australia': 3,\n",
    "    'Sri Lanka': 4,\n",
    "    'Pakistan': 5,\n",
    "    'South Africa': 6,\n",
    "    'Afghanistan': 7,\n",
    "    'England': 8,\n",
    "    'West Indies': 9,\n",
    "    'Bangladesh': 10\n",
    "}\n",
    "df['team1_rank'] = df['Team1'].map(icc_ranks)\n",
    "df['team2_rank'] = df['Team2'].map(icc_ranks)\n",
    "\n",
    "# Remove matches with unknown team ranks\n",
    "df = df.dropna(subset=['team1_rank', 'team2_rank'])\n",
    "\n",
    "# Rank difference feature\n",
    "df['rank_diff'] = df['team2_rank'] - df['team1_rank']\n",
    "\n",
    "# Binary target: Did Team1 win?\n",
    "df['target'] = df.apply(lambda row: 1 if row['Winner'] == row['Team1'] else 0, axis=1)\n",
    "\n",
    "# ------------------ Step 3: Feature Selection ------------------\n",
    "features = ['Avg_Temp_C', 'home_advantage', 'won_toss', 'team1_rank', 'team2_rank', 'rank_diff']\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# ------------------ Step 4: Preprocessing for SVM/XGBoost ------------------\n",
    "\n",
    "# Normalize features (important for SVM, not strictly needed for XGBoost but keeps pipeline consistent)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Optional: balance the dataset if class imbalance is present\n",
    "class_counts = Counter(y)\n",
    "print(\"Class distribution:\", class_counts)\n",
    "\n",
    "# Export preprocessed data\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=features)\n",
    "X_scaled_df['target'] = y.values\n",
    "X_scaled_df.to_csv(\"preprocessed_cricket_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ Preprocessing complete. Saved to 'preprocessed_cricket_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6451c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SVM Training ---\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "SVM Accuracy: 0.6049528301886793\n",
      "SVM Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.61       423\n",
      "           1       0.61      0.60      0.60       425\n",
      "\n",
      "    accuracy                           0.60       848\n",
      "   macro avg       0.60      0.60      0.60       848\n",
      "weighted avg       0.60      0.60      0.60       848\n",
      "\n",
      "\n",
      "--- XGBoost Training ---\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.6367924528301887\n",
      "XGBoost Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63       423\n",
      "           1       0.63      0.65      0.64       425\n",
      "\n",
      "    accuracy                           0.64       848\n",
      "   macro avg       0.64      0.64      0.64       848\n",
      "weighted avg       0.64      0.64      0.64       848\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:21:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgboost_model.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# ------------------ Step 1: Load Preprocessed Data ------------------\n",
    "data = pd.read_csv(\"preprocessed_cricket_data.csv\")\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "\n",
    "# ------------------ Step 2: Train/Test Split ------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------ Step 3: SVM Training ------------------\n",
    "print(\"\\n--- SVM Training ---\")\n",
    "svm = SVC(kernel='rbf', probability=True)\n",
    "svm_params = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']}\n",
    "svm_grid = GridSearchCV(svm, svm_params, cv=5, scoring='accuracy', verbose=1)\n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "svm_best = svm_grid.best_estimator_\n",
    "y_pred_svm = svm_best.predict(X_test)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"SVM Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# ------------------ Step 4: XGBoost Training ------------------\n",
    "print(\"\\n--- XGBoost Training ---\")\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', tree_method='hist')\n",
    "xgb_params = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb, xgb_params, cv=5, scoring='accuracy', verbose=1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "y_pred_xgb = xgb_best.predict(X_test)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# ------------------ Step 5: Optional Save ------------------\n",
    "import joblib\n",
    "joblib.dump(svm_best, \"svm_model.pkl\")\n",
    "joblib.dump(xgb_best, \"xgboost_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "303f0740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SVM Training ---\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "SVM Accuracy: 0.6049528301886793\n",
      "SVM Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.61       423\n",
      "           1       0.61      0.60      0.60       425\n",
      "\n",
      "    accuracy                           0.60       848\n",
      "   macro avg       0.60      0.60      0.60       848\n",
      "weighted avg       0.60      0.60      0.60       848\n",
      "\n",
      "\n",
      "--- XGBoost Training ---\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:729: UserWarning: [12:24:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.6438679245283019\n",
      "XGBoost Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.61      0.63       423\n",
      "           1       0.64      0.67      0.65       425\n",
      "\n",
      "    accuracy                           0.64       848\n",
      "   macro avg       0.64      0.64      0.64       848\n",
      "weighted avg       0.64      0.64      0.64       848\n",
      "\n",
      "\n",
      "Models and scaler saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# ------------------ Step 1: Load & Clean Dataset ------------------\n",
    "df = pd.read_csv(\"final_odi_matches_with_full_weather2.csv\")\n",
    "\n",
    "# Drop missing values in critical fields\n",
    "df = df.dropna(subset=['Match Winner', 'Team1 Name', 'Team2 Name', 'Avg_Temp_C'])\n",
    "df['Avg_Temp_C'] = df['Avg_Temp_C'].replace(-99, np.nan)\n",
    "df = df.dropna(subset=['Avg_Temp_C'])\n",
    "\n",
    "# Rename for consistency\n",
    "df.rename(columns={\n",
    "    'Team1 Name': 'Team1',\n",
    "    'Team2 Name': 'Team2',\n",
    "    'Match Winner': 'Winner',\n",
    "    'Toss Winner': 'TossWinner',\n",
    "    'Match Venue (Country)': 'VenueCountry'\n",
    "}, inplace=True)\n",
    "\n",
    "# ------------------ Step 2: Feature Engineering ------------------\n",
    "df['home_advantage'] = df.apply(\n",
    "    lambda row: 1 if pd.notna(row['VenueCountry']) and row['VenueCountry'].lower() in row['Team1'].lower() else 0,\n",
    "    axis=1\n",
    ")\n",
    "df['won_toss'] = df.apply(lambda row: 1 if row['TossWinner'] == row['Team1'] else 0, axis=1)\n",
    "\n",
    "# Updated ICC ranking from image\n",
    "team_rank = {\n",
    "    'India': 1,\n",
    "    'New Zealand': 2,\n",
    "    'Australia': 3,\n",
    "    'Sri Lanka': 4,\n",
    "    'Pakistan': 5,\n",
    "    'South Africa': 6,\n",
    "    'Afghanistan': 7,\n",
    "    'England': 8,\n",
    "    'West Indies': 9,\n",
    "    'Bangladesh': 10\n",
    "}\n",
    "df['team1_rank'] = df['Team1'].map(team_rank)\n",
    "df['team2_rank'] = df['Team2'].map(team_rank)\n",
    "df = df.dropna(subset=['team1_rank', 'team2_rank'])\n",
    "\n",
    "df['rank_diff'] = df['team2_rank'] - df['team1_rank']\n",
    "\n",
    "# Target variable: Did Team1 win?\n",
    "df['target'] = df.apply(lambda row: 1 if row['Winner'] == row['Team1'] else 0, axis=1)\n",
    "\n",
    "# ------------------ Step 3: Preprocessing ------------------\n",
    "features = ['Avg_Temp_C', 'home_advantage', 'won_toss', 'team1_rank', 'team2_rank', 'rank_diff']\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------ Step 4: SVM Training ------------------\n",
    "print(\"\\n--- SVM Training ---\")\n",
    "svm = SVC(kernel='rbf', probability=True)\n",
    "svm_params = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']}\n",
    "svm_grid = GridSearchCV(svm, svm_params, cv=5, scoring='accuracy', verbose=1)\n",
    "svm_grid.fit(X_train, y_train)\n",
    "svm_best = svm_grid.best_estimator_\n",
    "y_pred_svm = svm_best.predict(X_test)\n",
    "\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"SVM Report:\\n\", classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# ------------------ Step 5: XGBoost Training ------------------\n",
    "print(\"\\n--- XGBoost Training ---\")\n",
    "xgb = XGBClassifier(eval_metric='logloss', tree_method='hist', device='cuda')\n",
    "xgb_params = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1]\n",
    "}\n",
    "xgb_grid = GridSearchCV(xgb, xgb_params, cv=5, scoring='accuracy', verbose=1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "y_pred_xgb = xgb_best.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Report:\\n\", classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# ------------------ Step 6: Save Models ------------------\n",
    "joblib.dump(svm_best, \"svm_model.pkl\")\n",
    "joblib.dump(xgb_best, \"xgboost_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"\\nModels and scaler saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eadae123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Random Forest Training ---\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Random Forest Accuracy: 0.6615566037735849\n",
      "Random Forest Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       423\n",
      "           1       0.65      0.70      0.68       425\n",
      "\n",
      "    accuracy                           0.66       848\n",
      "   macro avg       0.66      0.66      0.66       848\n",
      "weighted avg       0.66      0.66      0.66       848\n",
      "\n",
      "\n",
      "Random Forest model and scaler saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# ------------------ Step 1: Load & Clean Dataset ------------------\n",
    "df = pd.read_csv(\"final_odi_matches_with_full_weather2.csv\")\n",
    "\n",
    "# Drop missing values in critical fields\n",
    "df = df.dropna(subset=['Match Winner', 'Team1 Name', 'Team2 Name', 'Avg_Temp_C'])\n",
    "df['Avg_Temp_C'] = df['Avg_Temp_C'].replace(-99, np.nan)\n",
    "df = df.dropna(subset=['Avg_Temp_C'])\n",
    "\n",
    "# Rename for consistency\n",
    "df.rename(columns={\n",
    "    'Team1 Name': 'Team1',\n",
    "    'Team2 Name': 'Team2',\n",
    "    'Match Winner': 'Winner',\n",
    "    'Toss Winner': 'TossWinner',\n",
    "    'Match Venue (Country)': 'VenueCountry'\n",
    "}, inplace=True)\n",
    "\n",
    "# ------------------ Step 2: Feature Engineering ------------------\n",
    "df['home_advantage'] = df.apply(\n",
    "    lambda row: 1 if pd.notna(row['VenueCountry']) and row['VenueCountry'].lower() in row['Team1'].lower() else 0,\n",
    "    axis=1\n",
    ")\n",
    "df['won_toss'] = df.apply(lambda row: 1 if row['TossWinner'] == row['Team1'] else 0, axis=1)\n",
    "\n",
    "# Updated ICC ranking from image\n",
    "team_rank = {\n",
    "    'India': 1,\n",
    "    'New Zealand': 2,\n",
    "    'Australia': 3,\n",
    "    'Sri Lanka': 4,\n",
    "    'Pakistan': 5,\n",
    "    'South Africa': 6,\n",
    "    'Afghanistan': 7,\n",
    "    'England': 8,\n",
    "    'West Indies': 9,\n",
    "    'Bangladesh': 10\n",
    "}\n",
    "df['team1_rank'] = df['Team1'].map(team_rank)\n",
    "df['team2_rank'] = df['Team2'].map(team_rank)\n",
    "df = df.dropna(subset=['team1_rank', 'team2_rank'])\n",
    "\n",
    "df['rank_diff'] = df['team2_rank'] - df['team1_rank']\n",
    "\n",
    "# Target variable: Did Team1 win?\n",
    "df['target'] = df.apply(lambda row: 1 if row['Winner'] == row['Team1'] else 0, axis=1)\n",
    "\n",
    "# ------------------ Step 3: Preprocessing ------------------\n",
    "features = ['Avg_Temp_C', 'home_advantage', 'won_toss', 'team1_rank', 'team2_rank', 'rank_diff']\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------ Step 4: Random Forest Training ------------------\n",
    "print(\"\\n--- Random Forest Training ---\")\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_best = rf_grid.best_estimator_\n",
    "y_pred_rf = rf_best.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# ------------------ Step 5: Save Model ------------------\n",
    "joblib.dump(rf_best, \"random_forest_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"\\nRandom Forest model and scaler saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1d1fdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocky's pc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [12:39:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Ensemble Model Evaluation ---\n",
      "Accuracy: 0.6509433962264151\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.64       423\n",
      "           1       0.64      0.68      0.66       425\n",
      "\n",
      "    accuracy                           0.65       848\n",
      "   macro avg       0.65      0.65      0.65       848\n",
      "weighted avg       0.65      0.65      0.65       848\n",
      "\n",
      "\n",
      "Ensemble model and scaler saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "# ------------------ Step 1: Load & Clean Dataset ------------------\n",
    "df = pd.read_csv(\"final_odi_matches_with_full_weather2.csv\")\n",
    "\n",
    "df = df.dropna(subset=['Match Winner', 'Team1 Name', 'Team2 Name', 'Avg_Temp_C'])\n",
    "df['Avg_Temp_C'] = df['Avg_Temp_C'].replace(-99, np.nan)\n",
    "df = df.dropna(subset=['Avg_Temp_C'])\n",
    "\n",
    "df.rename(columns={\n",
    "    'Team1 Name': 'Team1',\n",
    "    'Team2 Name': 'Team2',\n",
    "    'Match Winner': 'Winner',\n",
    "    'Toss Winner': 'TossWinner',\n",
    "    'Match Venue (Country)': 'VenueCountry'\n",
    "}, inplace=True)\n",
    "\n",
    "# ------------------ Step 2: Feature Engineering ------------------\n",
    "df['home_advantage'] = df.apply(\n",
    "    lambda row: 1 if pd.notna(row['VenueCountry']) and row['VenueCountry'].lower() in row['Team1'].lower() else 0,\n",
    "    axis=1\n",
    ")\n",
    "df['won_toss'] = df.apply(lambda row: 1 if row['TossWinner'] == row['Team1'] else 0, axis=1)\n",
    "\n",
    "team_rank = {\n",
    "    'India': 1, 'New Zealand': 2, 'Australia': 3, 'Sri Lanka': 4,\n",
    "    'Pakistan': 5, 'South Africa': 6, 'Afghanistan': 7,\n",
    "    'England': 8, 'West Indies': 9, 'Bangladesh': 10\n",
    "}\n",
    "df['team1_rank'] = df['Team1'].map(team_rank)\n",
    "df['team2_rank'] = df['Team2'].map(team_rank)\n",
    "df = df.dropna(subset=['team1_rank', 'team2_rank'])\n",
    "df['rank_diff'] = df['team2_rank'] - df['team1_rank']\n",
    "df['target'] = df.apply(lambda row: 1 if row['Winner'] == row['Team1'] else 0, axis=1)\n",
    "\n",
    "# ------------------ Step 3: Preprocessing ------------------\n",
    "features = ['Avg_Temp_C', 'home_advantage', 'won_toss', 'team1_rank', 'team2_rank', 'rank_diff']\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ------------------ Step 4: Define Base Models ------------------\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "xgb = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "svm = SVC(C=1.0, probability=True, kernel='rbf', random_state=42)\n",
    "\n",
    "# ------------------ Step 5: Ensemble Model ------------------\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[('rf', rf), ('xgb', xgb), ('svm', svm)],\n",
    "    voting='soft'  # Use predicted probabilities\n",
    ")\n",
    "\n",
    "ensemble.fit(X_train, y_train)\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Ensemble Model Evaluation ---\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ------------------ Step 6: Save Ensemble ------------------\n",
    "joblib.dump(ensemble, \"ensemble_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"\\nEnsemble model and scaler saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902a3339",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# ------------------ Step 1: Load Dataset ------------------\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "\n",
    "# ------------------ Step 1: Load Dataset ------------------\n",
    "df = pd.read_csv(\"final_odi_matches_with_full_weather2.csv\")\n",
    "\n",
    "# ------------------ Step 2: Preprocessing ------------------\n",
    "df = df.dropna(subset=['Match Winner', 'Team1 Name', 'Team2 Name'])\n",
    "df['Avg_Temp_C'] = df['Avg_Temp_C'].replace(-99, np.nan)\n",
    "df = df.dropna(subset=['Avg_Temp_C'])\n",
    "\n",
    "df.rename(columns={\n",
    "    'Team1 Name': 'Team1',\n",
    "    'Team2 Name': 'Team2',\n",
    "    'Match Winner': 'Winner',\n",
    "    'Toss Winner': 'TossWinner',\n",
    "    'Match Venue (Country)': 'VenueCountry'\n",
    "}, inplace=True)\n",
    "\n",
    "# Feature engineering\n",
    "df['home_advantage'] = df.apply(lambda row: 1 if pd.notna(row['VenueCountry']) and row['VenueCountry'].lower() in row['Team1'].lower() else 0, axis=1)\n",
    "df['won_toss'] = df.apply(lambda row: 1 if row['TossWinner'] == row['Team1'] else 0, axis=1)\n",
    "\n",
    "team_rank = {\n",
    "    'India': 1, 'New Zealand': 2, 'Australia': 3, 'Sri Lanka': 4,\n",
    "    'Pakistan': 5, 'South Africa': 6, 'Afghanistan': 7,\n",
    "    'England': 8, 'West Indies': 9, 'Bangladesh': 10\n",
    "}\n",
    "df['team1_rank'] = df['Team1'].map(team_rank)\n",
    "df['team2_rank'] = df['Team2'].map(team_rank)\n",
    "df = df.dropna(subset=['team1_rank', 'team2_rank'])\n",
    "\n",
    "df['rank_diff'] = df['team2_rank'] - df['team1_rank']\n",
    "df['target'] = df.apply(lambda row: 1 if row['Winner'] == row['Team1'] else 0, axis=1)\n",
    "\n",
    "# ------------------ Step 3: Split Data ------------------\n",
    "features = ['Avg_Temp_C', 'home_advantage', 'won_toss', 'team1_rank', 'team2_rank', 'rank_diff']\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ------------------ Step 4: Hyperparameter Tuning ------------------\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [6, 10, -1],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 50, 100]\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(boosting_type='gbdt', objective='binary', random_state=42)\n",
    "grid = GridSearchCV(estimator=lgbm, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1, verbose=1)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# ------------------ Step 5: Evaluate ------------------\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ------------------ Step 6: Save Model ------------------\n",
    "joblib.dump(best_model, \"lightgbmlarge_tuned_model.pkl\")\n",
    "print(\"📦 Model saved as lightgbmlarge_tuned_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
